{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "cc964c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.misc import derivative\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import make_regression "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46199e1b",
   "metadata": {},
   "source": [
    "## gradient descent scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "03fc662b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_regression(n_samples=300, n_features=3, n_informative=1, random_state=0, noise=35) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "59bd561f",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha =0.001\n",
    "theta = np.random.random (4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "923d25a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add intercept \n",
    "intercept = np.ones(300)\n",
    "X = np.insert(X, 0, intercept, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "dada19f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yhat(x, theta):\n",
    "    yhat_ = np.dot(x, theta)\n",
    "    return yhat_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "0c7b48ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_func(x, loss):\n",
    "    #m = x.shape[0]\n",
    "    #cost_ = (1/2)*sum((y-yhat_)**2)\n",
    "    #cost_ = np.sum(loss ** 2) / (2 * m)  # cost\n",
    "    cost_ = np.sum(loss ** 2) / 2  \n",
    "    return cost_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "3c81bf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch \n",
    "def gradient_desc(x, loss):\n",
    "    #m = x.shape[0]\n",
    "    #gd = np.dot(loss, x)/m\n",
    "    gd = np.dot(loss, x)\n",
    "    return gd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "id": "c02afd5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 593,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(loss, X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "c2864b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((300,), (300, 4))"
      ]
     },
     "execution_count": 591,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.shape, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "9c896e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0 | J: 1645999.792 | theta: [0.94493098 0.88729296 0.79568579 0.82168559] | diff: 1463010.250\n",
      "iter 5 | J: 223521.053 | theta: [ 2.40742443 -3.50133518 82.56189554  0.76489359] | diff: 41515.443\n",
      "iter 10 | J: 184273.813 | theta: [ 2.49363886 -1.9878901  96.07182834 -0.64378315] | diff: 1254.994\n",
      "iter 15 | J: 183034.181 | theta: [ 2.47235192 -1.41171442 98.38735868 -1.14062762] | diff: 42.266\n",
      "iter 20 | J: 182991.193 | theta: [ 2.45820944 -1.26830469 98.7970033  -1.27612501] | diff: 1.528\n",
      "iter 25 | J: 182989.606 | theta: [ 2.45260193 -1.23751813 98.87139044 -1.310001  ] | diff: 0.058\n",
      "iter 30 | J: 182989.545 | theta: [ 2.45070362 -1.23143404 98.88518351 -1.31819794] | diff: 0.002\n",
      "iter 35 | J: 182989.542 | theta: [ 2.45011184 -1.23030708 98.88778403 -1.32016392] | diff: 0.000\n"
     ]
    }
   ],
   "source": [
    "## batch GD\n",
    "diff = float('inf')\n",
    "counter =0\n",
    "\n",
    "while diff > 0.00001 and counter < 100000:\n",
    "       \n",
    "    yhat_ = yhat(X, theta)\n",
    "    loss = y - yhat_\n",
    "    prev_cost = cost_\n",
    "    cost_ = cost_func(X, loss)\n",
    "    \n",
    "    diff = abs(prev_cost - cost_)\n",
    "    if counter %5 == 0: print(\"iter %s | J: %.3f | theta: %s | diff: %.3f\" % (counter, cost_, theta, diff))    \n",
    "    theta += alpha*gradient_desc(X, loss)\n",
    "    counter +=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "aa4bee8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.44986748581179, array([ 0.        , -1.23007861, 98.88840062, -1.32078901])]\n"
     ]
    }
   ],
   "source": [
    "# check the value w/ the gradient descent result\n",
    "lm = LinearRegression()\n",
    "lm.fit(X, y)\n",
    "print([lm.intercept_, lm.coef_])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
